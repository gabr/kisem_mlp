\section{Observations and Conclusions}
\label{ObservationsConclusions}

As a summary some observations and conclusions related to topic will be presented.

\subsection{Limitations}
\label{Limitations}

Neural networks are perfect in creating mathematical models based on sample set and also without it (unsupervised learning) but they cannot model all functions. For example generation of random value cannot be achieve by neural network. Also choosing the proper sample set is a very difficult task itself and we need to be aware of \textit{overfitting} problem.

\hyperref[sec:Training]{Error Back Propagation} algorithm is very old and simple algorithm. It works but it is not perfect. It not guarantee reaching global minimum just a local one. Its also very sensitive to initial values of neuron weights. The criteria to stop algorithm are also not exactly clear. \\
There exist various modifications of pure \hyperref[sec:Training]{EBP} algorithm which solves some of this problems.

